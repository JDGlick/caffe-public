{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import lmdb\n",
    "import os\n",
    "import sys\n",
    "from struct import *\n",
    "\n",
    "caffe_root='/usr/local/google/home/zyan/proj/caffe_private_recurrent_2d/'\n",
    "sys.path.append(caffe_root + 'python')\n",
    "from caffe import *\n",
    "sys.path.append(caffe_root + 'python/caffe/proto')\n",
    "import caffe_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir='/usr/local/google/home/zyan/data/mnist/'\n",
    "train_img_data='train-images.idx3-ubyte'\n",
    "train_img_label='train-labels.idx1-ubyte'\n",
    "test_img_data='t10k-images.idx3-ubyte'\n",
    "test_img_label='t10k-labels.idx1-ubyte'\n",
    "\n",
    "caffe_data_dir=caffe_root+'data/mnist_semantic_segmentation/'\n",
    "caffe_example_dir=caffe_root+'examples/mnist_semantic_segmentation/'\n",
    "train_img_save_dir='train_images/'\n",
    "test_img_save_dir='test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' save into individual mnist images\n",
    "'''\n",
    "def extract_images_and_labels(img_data_file, img_label_file, img_save_path, out_label_file):\n",
    "    if not os.path.exists(img_save_path):\n",
    "        os.mkdir(img_save_path)\n",
    "        \n",
    "    \n",
    "    with open(img_data_file,'rb') as f:\n",
    "        magic_num_str = f.read(4)\n",
    "        magic_num = (unpack('>i',magic_num_str))[0]\n",
    "        num_img_str = f.read(4)\n",
    "        num_img=(unpack('>i',num_img_str))[0]\n",
    "        num_row_str=f.read(4)\n",
    "        num_row=(unpack('>i',num_row_str))[0]\n",
    "        num_col_str=f.read(4)\n",
    "        num_col=(unpack('>i',num_col_str))[0]    \n",
    "        print magic_num\n",
    "        print num_img\n",
    "        print num_row\n",
    "        print num_col\n",
    "        byte = f.read(num_img*num_row*num_col)\n",
    "    \n",
    "    byte_c = 0\n",
    "    for i in range(num_img):\n",
    "        img = np.zeros((num_row,num_col),dtype=np.int32)\n",
    "        for h in range(num_row):\n",
    "            for w in range(num_col):\n",
    "                img[h,w]=(unpack('>B',byte[byte_c]))[0]\n",
    "                byte_c+=1\n",
    "        scipy.misc.imsave(img_save_path+'%d.bmp'%i, img)\n",
    "    \n",
    "    print 'open label file'\n",
    "    with open(img_label_file,'rb') as f_label_in:\n",
    "        magic_num_str = f_label_in.read(4)\n",
    "        magic_num = (unpack('>i',magic_num_str))[0]\n",
    "        num_img_str = f_label_in.read(4)\n",
    "        num_img=(unpack('>i',num_img_str))[0]\n",
    "        byte=f_label_in.read(num_img)\n",
    "    \n",
    "    print 'magic_num %d' % magic_num\n",
    "    print 'num_img %d' % num_img\n",
    "    \n",
    "    \n",
    "    with open(out_label_file,'w') as f_label_out:\n",
    "        labels=np.zeros((num_img),dtype=np.uint32)\n",
    "        for i in range(num_img):\n",
    "            labels[i]=(unpack('>B',byte[i]))[0]\n",
    "            f_label_out.write('%d\\n'% labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2051\n",
      "60000\n",
      "28\n",
      "28\n",
      "open label file\n",
      "magic_num 2049\n",
      "num_img 60000\n",
      "2051\n",
      "10000\n",
      "28\n",
      "28\n",
      "open label file\n",
      "magic_num 2049\n",
      "num_img 10000\n"
     ]
    }
   ],
   "source": [
    "extract_images_and_labels(data_dir+train_img_data, data_dir+train_img_label,\\\n",
    "                          caffe_data_dir+train_img_save_dir,caffe_data_dir+'train_labels.txt')\n",
    "extract_images_and_labels(data_dir+test_img_data, data_dir+test_img_label,\\\n",
    "                          caffe_data_dir+test_img_save_dir,caffe_data_dir+'test_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_database(img_data_file,img_label_file, out_database_name):\n",
    "    out_lmdb = lmdb.open(out_database_name, map_size=1024*1024*1024)\n",
    "    \n",
    "    with open(img_data_file,'rb') as f:\n",
    "        magic_num_str = f.read(4)\n",
    "        magic_num = (unpack('>i',magic_num_str))[0]\n",
    "        num_img_str = f.read(4)\n",
    "        num_img = (unpack('>i',num_img_str))[0]\n",
    "        num_row_str = f.read(4)\n",
    "        num_row = (unpack('>i',num_row_str))[0]\n",
    "        num_col_str = f.read(4)\n",
    "        num_col = (unpack('>i',num_col_str))[0]  \n",
    "        pix_byte = f.read(num_img*num_row*num_col)\n",
    "    print 'num_img %d' % num_img\n",
    "    print 'num_row %d num_col %d' % (num_row, num_col)\n",
    "        \n",
    "    labels = np.zeros((num_img), dtype = np.int32)\n",
    "    with open(img_label_file, 'rb') as f_label_in:\n",
    "        magic_num_str = f_label_in.read(4)\n",
    "        magic_num = (unpack('>i',magic_num_str))[0]\n",
    "        num_img_str = f_label_in.read(4)\n",
    "        num_img=(unpack('>i',num_img_str))[0]\n",
    "        label_byte=f_label_in.read(num_img)\n",
    "        for i in range(num_img):\n",
    "            labels[i] = (unpack('>B', label_byte[i]))[0]\n",
    "    print 'labels'\n",
    "    print labels[:100]\n",
    "    img_size = num_row * num_col\n",
    "    \n",
    "    batch_size = 500\n",
    "    num_batch = num_img / batch_size\n",
    "    byte_c, img_c = 0, 0\n",
    "    for i in range(num_batch):\n",
    "        print '%d out of %d batches ' % (i, num_batch)\n",
    "        with out_lmdb.begin(write=True) as txn:\n",
    "            for j in range(batch_size):\n",
    "                datum = caffe_pb2.SemanticLabelingDatum()\n",
    "                datum.channels = 1\n",
    "                datum.height = num_row\n",
    "                datum.width = num_col\n",
    "                datum.data = pix_byte[img_c * img_size:(img_c + 1) * img_size]\n",
    "                fg_c = 0\n",
    "                for h in range(num_row):\n",
    "                    for w in range(num_col):\n",
    "                        pix_val = (unpack('>B',pix_byte[byte_c]))[0]\n",
    "                        if pix_val > 0:\n",
    "                            datum.label.append(int(labels[img_c]))\n",
    "                            fg_c += 1\n",
    "                        else:\n",
    "                            datum.label.append(10) # background label\n",
    "                        byte_c += 1\n",
    "                txn.put('%05d'%img_c, datum.SerializeToString())\n",
    "                img_c += 1\n",
    "    \n",
    "    out_lmdb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_img 60000\n",
      "num_row 28 num_col 28\n",
      "0 out of 120 batches \n",
      "1 out of 120 batches \n",
      "2 out of 120 batches \n",
      "3 out of 120 batches \n",
      "4 out of 120 batches \n",
      "5 out of 120 batches \n",
      "6 out of 120 batches \n",
      "7 out of 120 batches \n",
      "8 out of 120 batches \n",
      "9 out of 120 batches \n",
      "10 out of 120 batches \n",
      "11 out of 120 batches \n",
      "12 out of 120 batches \n",
      "13 out of 120 batches \n",
      "14 out of 120 batches \n",
      "15 out of 120 batches \n",
      "16 out of 120 batches \n",
      "17 out of 120 batches \n",
      "18 out of 120 batches \n",
      "19 out of 120 batches \n",
      "20 out of 120 batches \n",
      "21 out of 120 batches \n",
      "22 out of 120 batches \n",
      "23 out of 120 batches \n",
      "24 out of 120 batches \n",
      "25 out of 120 batches \n",
      "26 out of 120 batches \n",
      "27 out of 120 batches \n",
      "28 out of 120 batches \n",
      "29 out of 120 batches \n",
      "30 out of 120 batches \n",
      "31 out of 120 batches \n",
      "32 out of 120 batches \n",
      "33 out of 120 batches \n",
      "34 out of 120 batches \n",
      "35 out of 120 batches \n",
      "36 out of 120 batches \n",
      "37 out of 120 batches \n",
      "38 out of 120 batches \n",
      "39 out of 120 batches \n",
      "40 out of 120 batches \n",
      "41 out of 120 batches \n",
      "42 out of 120 batches \n",
      "43 out of 120 batches \n",
      "44 out of 120 batches \n",
      "45 out of 120 batches \n",
      "46 out of 120 batches \n",
      "47 out of 120 batches \n",
      "48 out of 120 batches \n",
      "49 out of 120 batches \n",
      "50 out of 120 batches \n",
      "51 out of 120 batches \n",
      "52 out of 120 batches \n",
      "53 out of 120 batches \n",
      "54 out of 120 batches \n",
      "55 out of 120 batches \n",
      "56 out of 120 batches \n",
      "57 out of 120 batches \n",
      "58 out of 120 batches \n",
      "59 out of 120 batches \n",
      "60 out of 120 batches \n",
      "61 out of 120 batches \n",
      "62 out of 120 batches \n",
      "63 out of 120 batches \n",
      "64 out of 120 batches \n",
      "65 out of 120 batches \n",
      "66 out of 120 batches \n",
      "67 out of 120 batches \n",
      "68 out of 120 batches \n",
      "69 out of 120 batches \n",
      "70 out of 120 batches \n",
      "71 out of 120 batches \n",
      "72 out of 120 batches \n",
      "73 out of 120 batches \n",
      "74 out of 120 batches \n",
      "75 out of 120 batches \n",
      "76 out of 120 batches \n",
      "77 out of 120 batches \n",
      "78 out of 120 batches \n",
      "79 out of 120 batches \n",
      "80 out of 120 batches \n",
      "81 out of 120 batches \n",
      "82 out of 120 batches \n",
      "83 out of 120 batches \n",
      "84 out of 120 batches \n",
      "85 out of 120 batches \n",
      "86 out of 120 batches \n",
      "87 out of 120 batches \n",
      "88 out of 120 batches \n",
      "89 out of 120 batches \n",
      "90 out of 120 batches \n",
      "91 out of 120 batches \n",
      "92 out of 120 batches \n",
      "93 out of 120 batches \n",
      "94 out of 120 batches \n",
      "95 out of 120 batches \n",
      "96 out of 120 batches \n",
      "97 out of 120 batches \n",
      "98 out of 120 batches \n",
      "99 out of 120 batches \n",
      "100 out of 120 batches \n",
      "101 out of 120 batches \n",
      "102 out of 120 batches \n",
      "103 out of 120 batches \n",
      "104 out of 120 batches \n",
      "105 out of 120 batches \n",
      "106 out of 120 batches \n",
      "107 out of 120 batches \n",
      "108 out of 120 batches \n",
      "109 out of 120 batches \n",
      "110 out of 120 batches \n",
      "111 out of 120 batches \n",
      "112 out of 120 batches \n",
      "113 out of 120 batches \n",
      "114 out of 120 batches \n",
      "115 out of 120 batches \n",
      "116 out of 120 batches \n",
      "117 out of 120 batches \n",
      "118 out of 120 batches \n",
      "119 out of 120 batches \n",
      "num_img 10000\n",
      "num_row 28 num_col 28\n",
      "0 out of 20 batches \n",
      "1 out of 20 batches \n",
      "2 out of 20 batches \n",
      "3 out of 20 batches \n",
      "4 out of 20 batches \n",
      "5 out of 20 batches \n",
      "6 out of 20 batches \n",
      "7 out of 20 batches \n",
      "8 out of 20 batches \n",
      "9 out of 20 batches \n",
      "10 out of 20 batches \n",
      "11 out of 20 batches \n",
      "12 out of 20 batches \n",
      "13 out of 20 batches \n",
      "14 out of 20 batches \n",
      "15 out of 20 batches \n",
      "16 out of 20 batches \n",
      "17 out of 20 batches \n",
      "18 out of 20 batches \n",
      "19 out of 20 batches \n"
     ]
    }
   ],
   "source": [
    "# prepare_database(data_dir+train_img_data, data_dir+train_img_label,\\\n",
    "#                 caffe_example_dir+'train_lmdb')\n",
    "prepare_database(data_dir+test_img_data, data_dir+test_img_label,\\\n",
    "                caffe_example_dir+'test_lmdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
