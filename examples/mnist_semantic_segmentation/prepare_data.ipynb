{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import lmdb\n",
    "import os\n",
    "import sys\n",
    "from struct import *\n",
    "\n",
    "caffe_root='/usr/local/google/home/zyan/proj/caffe_private_recurrent_2d/'\n",
    "sys.path.append(caffe_root + 'python')\n",
    "from caffe import *\n",
    "sys.path.append(caffe_root + 'python/caffe/proto')\n",
    "import caffe_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir='/usr/local/google/home/zyan/data/mnist/'\n",
    "train_img_data='train-images.idx3-ubyte'\n",
    "train_img_label='train-labels.idx1-ubyte'\n",
    "test_img_data='t10k-images.idx3-ubyte'\n",
    "test_img_label='t10k-labels.idx1-ubyte'\n",
    "\n",
    "caffe_data_dir=caffe_root+'data/mnist_semantic_segmentation/'\n",
    "caffe_example_dir=caffe_root+'examples/mnist_semantic_segmentation/'\n",
    "train_img_save_dir='train_images/'\n",
    "test_img_save_dir='test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' save into individual mnist images\n",
    "'''\n",
    "def extract_images_and_labels(img_data_file, img_label_file, img_save_path, out_label_file):\n",
    "    if not os.path.exists(img_save_path):\n",
    "        os.mkdir(img_save_path)\n",
    "        \n",
    "    \n",
    "    with open(img_data_file,'rb') as f:\n",
    "        magic_num_str = f.read(4)\n",
    "        magic_num = (unpack('>i',magic_num_str))[0]\n",
    "        num_img_str = f.read(4)\n",
    "        num_img=(unpack('>i',num_img_str))[0]\n",
    "        num_row_str=f.read(4)\n",
    "        num_row=(unpack('>i',num_row_str))[0]\n",
    "        num_col_str=f.read(4)\n",
    "        num_col=(unpack('>i',num_col_str))[0]    \n",
    "        print magic_num\n",
    "        print num_img\n",
    "        print num_row\n",
    "        print num_col\n",
    "        byte = f.read(num_img*num_row*num_col)\n",
    "    \n",
    "    byte_c = 0\n",
    "    for i in range(num_img):\n",
    "        img = np.zeros((num_row,num_col),dtype=np.int32)\n",
    "        for h in range(num_row):\n",
    "            for w in range(num_col):\n",
    "                img[h,w]=(unpack('>B',byte[byte_c]))[0]\n",
    "                byte_c+=1\n",
    "        scipy.misc.imsave(img_save_path+'%d.bmp'%i, img)\n",
    "    \n",
    "    print 'open label file'\n",
    "    with open(img_label_file,'rb') as f_label_in:\n",
    "        magic_num_str = f_label_in.read(4)\n",
    "        magic_num = (unpack('>i',magic_num_str))[0]\n",
    "        num_img_str = f_label_in.read(4)\n",
    "        num_img=(unpack('>i',num_img_str))[0]\n",
    "        byte=f_label_in.read(num_img)\n",
    "    \n",
    "    print 'magic_num %d' % magic_num\n",
    "    print 'num_img %d' % num_img\n",
    "    \n",
    "    \n",
    "    with open(out_label_file,'w') as f_label_out:\n",
    "        labels=np.zeros((num_img),dtype=np.uint32)\n",
    "        for i in range(num_img):\n",
    "            labels[i]=(unpack('>B',byte[i]))[0]\n",
    "            f_label_out.write('%d\\n'% labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2051\n",
      "60000\n",
      "28\n",
      "28\n",
      "open label file\n",
      "magic_num 2049\n",
      "num_img 60000\n",
      "2051\n",
      "10000\n",
      "28\n",
      "28\n",
      "open label file\n",
      "magic_num 2049\n",
      "num_img 10000\n"
     ]
    }
   ],
   "source": [
    "extract_images_and_labels(data_dir+train_img_data, data_dir+train_img_label,\\\n",
    "                          caffe_data_dir+train_img_save_dir,caffe_data_dir+'train_labels.txt')\n",
    "extract_images_and_labels(data_dir+test_img_data, data_dir+test_img_label,\\\n",
    "                          caffe_data_dir+test_img_save_dir,caffe_data_dir+'test_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_database(img_data_file,img_label_file, out_database_name):\n",
    "    out_lmdb = lmdb.open(out_database_name, map_size=1024*1024*1024)\n",
    "    \n",
    "    with open(img_data_file,'rb') as f:\n",
    "        magic_num_str = f.read(4)\n",
    "        magic_num = (unpack('>i',magic_num_str))[0]\n",
    "        num_img_str = f.read(4)\n",
    "        num_img = (unpack('>i',num_img_str))[0]\n",
    "        num_row_str = f.read(4)\n",
    "        num_row = (unpack('>i',num_row_str))[0]\n",
    "        num_col_str = f.read(4)\n",
    "        num_col = (unpack('>i',num_col_str))[0]  \n",
    "        pix_byte = f.read(num_img*num_row*num_col)\n",
    "    print 'num_img %d' % num_img\n",
    "    print 'num_row %d num_col %d' % (num_row, num_col)\n",
    "        \n",
    "    labels = np.zeros((num_img), dtype = np.int32)\n",
    "    with open(img_label_file, 'rb') as f_label_in:\n",
    "        magic_num_str = f_label_in.read(4)\n",
    "        magic_num = (unpack('>i',magic_num_str))[0]\n",
    "        num_img_str = f_label_in.read(4)\n",
    "        num_img=(unpack('>i',num_img_str))[0]\n",
    "        label_byte=f_label_in.read(num_img)\n",
    "        for i in range(num_img):\n",
    "            labels[i] = (unpack('>B', label_byte[i]))[0]\n",
    "    print 'labels'\n",
    "    print labels[:100]\n",
    "    img_size = num_row * num_col\n",
    "    \n",
    "    batch_size = 500\n",
    "    num_batch = num_img / batch_size\n",
    "    byte_c, img_c = 0, 0\n",
    "    for i in range(num_batch):\n",
    "        print '%d out of %d batches ' % (i, num_batch)\n",
    "        with out_lmdb.begin(write=True) as txn:\n",
    "            for j in range(batch_size):\n",
    "                datum = caffe_pb2.SemanticLabelingDatum()\n",
    "                datum.channels = 1\n",
    "                datum.height = num_row\n",
    "                datum.width = num_col\n",
    "                datum.data = pix_byte[img_c * img_size:(img_c + 1) * img_size]\n",
    "                fg_c = 0\n",
    "                for h in range(num_row):\n",
    "                    for w in range(num_col):\n",
    "                        pix_val = (unpack('>B',pix_byte[byte_c]))[0]\n",
    "                        if pix_val > 0:\n",
    "                            datum.label.append(int(labels[img_c]))\n",
    "                            fg_c += 1\n",
    "                        else:\n",
    "                            datum.label.append(10) # background label\n",
    "                        byte_c += 1\n",
    "                txn.put('%05d'%img_c, datum.SerializeToString())\n",
    "                img_c += 1\n",
    "    \n",
    "    out_lmdb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_img 10000\n",
      "num_row 28 num_col 28\n",
      "labels\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "0 out of 20 batches \n",
      "1 out of 20 batches \n",
      "2 out of 20 batches \n",
      "3 out of 20 batches \n",
      "4 out of 20 batches \n",
      "5 out of 20 batches \n",
      "6 out of 20 batches \n",
      "7 out of 20 batches \n",
      "8 out of 20 batches \n",
      "9 out of 20 batches \n",
      "10 out of 20 batches \n",
      "11 out of 20 batches \n",
      "12 out of 20 batches \n",
      "13 out of 20 batches \n",
      "14 out of 20 batches \n",
      "15 out of 20 batches \n",
      "16 out of 20 batches \n",
      "17 out of 20 batches \n",
      "18 out of 20 batches \n",
      "19 out of 20 batches \n"
     ]
    }
   ],
   "source": [
    "# prepare_database(data_dir+train_img_data, data_dir+train_img_label,\\\n",
    "#                 caffe_example_dir+'train_lmdb')\n",
    "prepare_database(data_dir+test_img_data, data_dir+test_img_label,\\\n",
    "                caffe_example_dir+'test_lmdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
