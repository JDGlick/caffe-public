{
 "metadata": {
  "name": "",
  "signature": "sha256:d80cb98b0a0bdefc5ab768b38eed83a64dca90e2da8306f80d521ec2aa3311d1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "import numpy.random as rd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import scipy.linalg\n",
      "from sklearn.cluster import k_means\n",
      "from sklearn.cluster import *\n",
      "import copy\n",
      "import leveldb\n",
      "\n",
      "# Make sure that caffe is on the python path:\n",
      "caffe_root = os.environ['CAFFE_PROJ_DIR']\n",
      "caffe_local_root = os.environ['CAFFE_LOCAL_PROJ_DIR']\n",
      "print 'caffe_root',caffe_root\n",
      "print 'caffe_local_root',caffe_local_root\n",
      "\n",
      "import sys\n",
      "sys.path.append(caffe_root + 'python')\n",
      "sys.path.append(caffe_root + 'python/util')\n",
      "import caffe\n",
      "from util_func import *\n",
      "\n",
      "sys.path.append(caffe_root + 'python/caffe/proto')\n",
      "import caffe_pb2\n",
      "\n",
      "plt.rcParams['figure.figsize'] = (5, 5)\n",
      "plt.rcParams['image.interpolation'] = 'nearest'\n",
      "plt.rcParams['image.cmap'] = 'gray'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "caffe_root /home/zyan3/proj/caffe_private_hdcnn/\n",
        "caffe_local_root /home/zyan3/local/proj/caffe_private_hdcnn/\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_dir=caffe_root+'models/VGG_ILSVRC_16_layers/211839e770f7b538e2d8/'\n",
      "example_dir=caffe_root+'examples/imagenet/'\n",
      "num_val, num_class = 50000, 1000\n",
      "print 'model_dir ',model_dir\n",
      "print 'example_dir ',example_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model_dir  /home/zyan3/proj/caffe_private_hdcnn/models/VGG_ILSVRC_16_layers/211839e770f7b538e2d8/\n",
        "example_dir  /home/zyan3/proj/caffe_private_hdcnn/examples/imagenet/\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "read 100-class probabilities for validation images from leveldb\n",
      "'''\n",
      "val_prob=np.zeros((num_val,num_class))\n",
      "db = leveldb.LevelDB(caffe_root + 'examples/imagenet/VGG_16_layer_val_fc8_leveldb')\n",
      "\n",
      "for i in range(num_val):\n",
      "    key='%d'%i\n",
      "    str_data=db.Get(key)\n",
      "    datum = caffe_pb2.Datum()\n",
      "    datum.ParseFromString(str_data)    \n",
      "    for j in range(num_class):\n",
      "        val_prob[i,j]=datum.float_data[j]\n",
      "val_prob=softmax(val_prob)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compute softmax probabilities\n",
        "num 50000 dim 1000\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''load fine label names'''\n",
      "label_names = []\n",
      "f=open(caffe_root + 'data/ilsvrc12/synset_words.txt')\n",
      "for line in f:\n",
      "    label_names += [line[:-1]]\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''load (name, label) for training/validation images'''\n",
      "train_img_list= caffe_root + 'data/ilsvrc12/train.txt'\n",
      "val_img_list = caffe_root + 'data/ilsvrc12/val.txt'\n",
      "train_img_names,train_img_labels=read_val_image_list(train_img_list)\n",
      "val_img_names,val_img_labels=read_val_image_list(val_img_list)\n",
      "train_img_labels,val_img_labels=np.asarray(train_img_labels),np.asarray(val_img_labels)\n",
      "class_num = np.max(train_img_labels) + 1\n",
      "print '%d classes' % class_num"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1281167 validation images \n",
        "50000 validation images \n",
        "1000 classes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_k = 5\n",
      "pred_labels_val = np.zeros((num_val, top_k),dtype=np.int32)\n",
      "accuracy = 0.\n",
      "for i in range(num_val):\n",
      "    idx=np.argsort(val_prob[i,:])[::-1]\n",
      "    pred_labels_val[i,:] = idx[:top_k]\n",
      "\n",
      "accuracies=top_k_accuracy(pred_labels_val,val_img_labels,[1,5])\n",
      "for k in [1,5]:\n",
      "    print 'k ',k\n",
      "    print 'top %d accuracy: %5.3f' % (k,accuracies[str(k)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "k  1\n",
        "top 1 accuracy: 0.679\n",
        "k  5\n",
        "top 5 accuracy: 0.877\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''plot confusion matrix'''\n",
      "confusion_mat = np.zeros((num_class,num_class))\n",
      "for i in range(num_class):\n",
      "    idx=np.nonzero(val_img_labels==i)[0]\n",
      "    pred_label_ = pred_labels_val[idx]\n",
      "    confusion_mat[i,:] = np.float64(np.bincount(pred_label_,minlength=num_class))/np.float64(len(idx))    \n",
      "plt.figure()\n",
      "plt.title('confusion matrix on validation set')\n",
      "plt.imshow(confusion_mat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dist_mat = 1.0 - confusion_mat\n",
      "'''set diagonal elements to 0'''\n",
      "dist_mat[range(num_class),range(num_class)]=0\n",
      "dist_mat = 0.5 * (dist_mat + dist_mat.T)\n",
      "plt.figure()\n",
      "plt.title('distance matrix on validation set')\n",
      "plt.imshow(dist_mat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''Laplacian eigenmap dimensionality reduction\n",
      "construct adjacency graph W (symmetric) using k-NN'''\n",
      "W=np.zeros((num_class,num_class))\n",
      "\n",
      "''' 9 clusteres'''\n",
      "k_nn, t, dim = 5, 0.9, 4\n",
      "\n",
      "for i in range(num_class):\n",
      "    idx=np.argsort(dist_mat[i,:])[1:k_nn+1]\n",
      "    W[i,idx]=np.exp(-dist_mat[i,idx] / t)\n",
      "    W[idx,i]=W[i,idx]\n",
      "D=np.zeros(W.shape)\n",
      "for i in range(num_class):\n",
      "    D[i,i]=np.sum(W[i,:])\n",
      "L=D-W\n",
      "eig_val,eig_vec=scipy.linalg.eig(L,D)\n",
      "ftr=eig_vec[:,1:dim+1]\n",
      "print eig_vec[:,0] # the 1st eigenvector should be all ones\n",
      "eigval_cumsum = np.cumsum(np.real(eig_val))\n",
      "plt.plot(eigval_cumsum)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''affinity propagation clustering'''\n",
      "if 1: \n",
      "    '''9 clusters'''\n",
      "    affinity_propagation_cluster = AffinityPropagation(damping=0.75, max_iter=15000, convergence_iter=50, copy=True) \n",
      "    \n",
      "    cluster_labels = affinity_propagation_cluster.fit_predict(ftr)\n",
      "    unique_cluster_label = np.unique(cluster_labels)\n",
      "    n_cluster = unique_cluster_label.shape[0]\n",
      "    cluster_members=[None]*n_cluster\n",
      "\n",
      "    for i in range(n_cluster):\n",
      "        idx = np.nonzero(cluster_labels == unique_cluster_label[i])[0]\n",
      "        cluster_members[i]=list(idx)\n",
      "        print 'cluster %d size %d ' % (i, len(idx))\n",
      "        for j in range(len(idx)):\n",
      "            print '%s,' % label_names[idx[j]],\n",
      "        print ' '"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_gpu=2\n",
      "version ='v0.0'\n",
      "example_dir = caffe_root + 'examples/imagenet/'\n",
      "print 'example_dir',example_dir\n",
      "if not os.path.exists(example_dir): \n",
      "    os.mkdir(example_dir)\n",
      "\n",
      "save_dir = model_dir + '%dclusters/'%n_cluster \n",
      "if not os.path.exists(save_dir):\n",
      "    os.mkdir(save_dir)\n",
      "save_dir += '%dclusters_%s/'%(n_cluster,version)\n",
      "if not os.path.exists(save_dir):\n",
      "    os.mkdir(save_dir)\n",
      "print 'save_dir',save_dir\n",
      "print 'n_cluster',n_cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "''' Adding extra classes to each branch to compensate for coarse misclassification at gating part\n",
      "For each branch, sort all classes out of branch based on likelihood that they're misclassified into the branch\n",
      "Take the top ones and also limit the total number of classes within each branch\n",
      "'''\n",
      "all_mb=range(num_class)\n",
      "\n",
      "# for 9 clusters\n",
      "score_thres=1.0/(5.0*n_cluster)\n",
      " \n",
      "max_exp_clu_size=80\n",
      "extra_cluster_members=[None]*n_cluster\n",
      "exp_cluster_members=[None]*n_cluster\n",
      "\n",
      "for i in range(n_cluster):\n",
      "    non_member = np.asarray(np.setdiff1d(range(num_class),cluster_members[i]))\n",
      "#     print non_member.shape\n",
      "    score=np.zeros((non_member.shape[0]))\n",
      "    for j in range(non_member.shape[0]):\n",
      "        idx=np.nonzero(val_img_labels==non_member[j])[0]\n",
      "        lc_prob=val_prob[idx,:][:,cluster_members[i]]\n",
      "        score[j]=np.mean(np.sum(lc_prob,axis=1))\n",
      "    score_sorted=np.sort(score)[::-1]\n",
      "    idx_sort=np.argsort(score)[::-1]\n",
      "    idx2=np.nonzero(score_sorted>=score_thres)[0]\n",
      "    if len(idx2)+len(cluster_members[i])> max_exp_clu_size:\n",
      "        idx2=idx2[:(max_exp_clu_size-len(cluster_members[i]))]\n",
      "    extra_cluster_members[i]=[non_member[idx_sort[id]] for id in idx2]\n",
      "    exp_cluster_members[i]=cluster_members[i]+extra_cluster_members[i]\n",
      "    assert len(exp_cluster_members[i])==np.unique(np.asarray(exp_cluster_members[i])).shape[0]\n",
      "\n",
      "total_member=sum([len(cluster) for cluster in exp_cluster_members])\n",
      "print 'total_member %d' % total_member\n",
      "plt.hist([len(cluster) for cluster in exp_cluster_members],bins=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_cluster_coverage(num_class,cluster_members,confusion_mat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_cluster_coverage(num_class,exp_cluster_members,confusion_mat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_2_clusterid = np.zeros((class_num))\n",
      "for i in range(n_cluster):\n",
      "    print 'cluster %d size %d' %(i, len(cluster_members[i]))\n",
      "    for j in range(len(cluster_members[i])):\n",
      "        label_2_clusterid[cluster_members[i][j]] = i\n",
      "\n",
      "label_2_clusterid_file = caffe_root + 'data/ilsvrc12/label_2_clusterid_%dclusters_VGG_16_layer.txt' % (n_cluster)\n",
      "\n",
      "f=open(label_2_clusterid_file,'w')\n",
      "for i in range(class_num):\n",
      "    f.write('%d\\n' % label_2_clusterid[i])\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''calculate coarse category classification accuracy when classification layer \n",
      "(FC layer) has one neuron for each fine category '''\n",
      "'''\n",
      "read 1000-class probabilities of 50K validation set images\n",
      "'''\n",
      "val_pred_lbs=np.argmax(val_prob,axis=1)\n",
      "\n",
      "fine_accu=sum([1 if gt==pred else 0 for (gt,pred) in zip(val_img_labels, val_pred_lbs)])/float(len(val_pred_lbs))\n",
      "coarse_accu=sum([1 if label_2_clusterid[gt]==label_2_clusterid[pred] else 0 for (gt,pred) in zip(val_img_labels,val_pred_lbs)])/float(len(val_pred_lbs))\n",
      "print 'fine classification accuracy %4.3f' % fine_accu\n",
      "print 'coarse classification accuracy %4.3f' % coarse_accu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''for each cluster, write down the labels it owns'''\n",
      "data_dir = caffe_root+'data/ilsvrc12/cluster_confusion_mat_%dclusters_VGG_16_layer/' % (n_cluster)\n",
      "if not os.path.exists(data_dir):\n",
      "    os.mkdir(data_dir)\n",
      "    \n",
      "for i in range(n_cluster):\n",
      "    f = open(data_dir + 'cluster%02d_labels.txt' % i,'w')\n",
      "    for j in range(len(cluster_members[i])):\n",
      "        f.write('%d\\n' % cluster_members[i][j])\n",
      "    f.close()\n",
      "    \n",
      "'''For each expanded cluster, prepare a training set with image's label remapped '''\n",
      "for i in range(n_cluster):\n",
      "    f=open(data_dir + 'exp_cluster%02d_label_map.txt' % i,'w')\n",
      "    for j in range(len(exp_cluster_members[i])):\n",
      "        f.write('%d %d\\n' % (exp_cluster_members[i][j],j))\n",
      "    f.close()    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vgg_16_layer_def_fn =model_dir + 'train_test.prototxt'\n",
      "vgg_16_layer_def = read_text(vgg_16_layer_def_fn)\n",
      "\n",
      "lay_nams=['conv1', 'cccp1','relu1','cccp2','relu2','pool1','drop1',\n",
      "          'conv2', 'cccp3','relu3','cccp4','relu4','pool2','drop2',\n",
      "          'conv3','cccp5','relu5','cccp6','relu6','poolg']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}